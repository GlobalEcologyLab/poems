---
title: "Workflow example for the Tasmanian thylacine"
author: "Global ChEC Lab"
date: "`r Sys.Date()`"
output: rmarkdown::html_document
geometry: margin=2cm
vignette: >
  %\VignetteIndexEntry{Thylacine example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this vignette we present a more advanced example of the *poems* workflow using a
population model of the historic decline of the *thylacine* in Tasmania, Australia.
The *thylacine* was a carnivorous marsupial that declined to presumed extinction
in response to European colonizer hunting and land use. As well as being hunted for the
exotic fur and skin trade, it was also considered a threat to livestock. Thus a 
government bounty was offered for eradicated *thylacine* during the period 1888 until 
1909 (Guiler 1985). We model these hunting and bounty dynamics via a bio-economic
approach adapted from Bulte, Horan, and Shogren (2003). We will build our model 
ensemble by selecting the simulations most congruent to expected extirpation/extinction
dates and changes (regression slopes) in the number of *thylacines* submitted during 
the bounty interval, derived from historic bounty, capture and sighting records [REF].

## Setup
We begin by loading the *poems* package and setting our output directory. We will also
set a flag for running the vignette in demonstration mode (default). When set to *TRUE*, 
pre-run simulation results are loaded rather than waiting (potentially hours) to run 
the full sample model set. Feel free to set this flag to *FALSE* to run your own
simulations. You may also change the number of samples generated, set the number of 
parallel cores available on your system, and set the simulation output directory.

```{r setup}
library(poems)
DEMONSTRATION <- TRUE # load pre-run data rather than running simulations
SAMPLES <- 10000
PARALLEL_CORES <- 2
OUTPUT_DIR <- tempdir()
```

## Workflow
As discussed in the simple example vignette, the *poems* workflow, which implements a 
pattern-oriented modeling (POM) approach (Grimm et al., 2005), is is summarized by the 
following six steps:

1. Build the population model for the study region.
1. Build generators for dynamically generating model parameters.
1. Sample model and generator parameters for each simulation.
1. Build a simulation manager to run each simulation.
1. Build a results manager to generate summary results (metrics).
1. Build a validator to select a model ensemble.

### Step 1: Build the population model for the study region
We start by building a model template (using the *PopulationModel* class) with fixed
model parameters and user-defined functions, including our bio-economic harvest 
function. Since our model is spatially explicit, we also need to define our study region
(via the *Region* class).

##### Tasmanian study region
First, we'll define our study region via a *raster* of 0.1 degree grid-cells for the
majority of Tasmania, once inhabited by the *thylacine*. This *raster* of Tasmania 
accompanies the *poems* package, and may be loaded via its variable name. In this 
vignette we will 'scope' data variables included in the package with *poems::* to 
highlight where they have come from, although this is unnecessary when the package is 
loaded (via *library(poems)*).

```{r, message = FALSE, fig.align = "center", fig.width = 4, fig.height = 4}
# Raster of Tasmania (note: islands removed where there was no evidence of thylacine
# occupancy).
raster::plot(poems::tasmania_raster, main = "Tasmania raster",
             xlab = "Longitude (degrees)", ylab = "Latitude (degrees)",
             colNA = "blue")
```

Note that when the *raster* is used as a template for the *Region* object, its occupiable
cell indices are set in the order in which they are stored in the *raster*.

```{r, message = FALSE, fig.align = "center", fig.width = 4, fig.height = 4}
# Tasmania study region (795 cells stored in the order shown)
region <- Region$new(template_raster = tasmania_raster)
raster::plot(region$region_raster, main = "Tasmanian study region (cell indices)",
             xlab = "Longitude (degrees)", ylab = "Latitude (degrees)",
             colNA = "blue")
```

The grid-cell size was selected as a reasonable approximation to *thylacine* 
territorial range (Guiler & Godard, 1998 ???).

##### IBRA bioregions
We partition our study region into Interim Bioregionalisation of Australia (IBRA) 
bioregions for several purposes. Our harvest function will distribute our simulated 
harvest across these bioregions. We will also use these IBRA bioregions to approximate 
patial differences in habitat suitability decline. Finally, in step 6, we will utilize
estimated extirpation dates for each IBRA bioregion when selecting our model ensemble.
A *raster* of the approximate distribution of our study region cells across IBRA 
bioregions, as well as a *data frame* containing information about each IBRA, are 
included with the *poems* package. Here we also collate lists of indices and the
number of cells for each bioregion.

```{r, message = FALSE, fig.align = "center", fig.width = 4, fig.height = 4}
# Tasmania study Interim Bioregionalisation of Australia (IBRA) bioregion cell
# distribution
ibra_raster <- poems::tasmania_ibra_raster
raster::plot(ibra_raster, main = "Tasmania study IBRA bioregions", colNA = "blue",
             xlab = "Longitude (degrees)", ylab = "Latitude (degrees)")
ibra_data <- poems::tasmania_ibra_data
ibra_data # examine

# Calculate cell indices and counts for IBRA bioregions
ibra_indices <- lapply(as.list(ibra_data$index),
                       function(i) {
                         which(ibra_raster[region$region_indices] == i)
                       })
ibra_indices[1:2] # examine
ibra_cells <- unlist(lapply(ibra_indices, length))
ibra_cells # examine
```

##### Density dependence function
Here we create a user-defined function for density dependence utilizing the logistic
approach (Ricker, 1954). Although the *poems* package has the Ricker logistic function
as a predefined function operating at the population grid-cell level (via 
*density_dependence = "logistic"*), this was found to be inadequate for our *thylacine*
model due to the low density of the *thylacine* at the grid-cell level. Instead our
density dependence function will operate at a neighbourhood level, where each 
cell's neighbourhood include its adjacent cells (thus up to 9 cells in total).
This approach considers the mobility of the *thylacine* when calculating annual
reproduction and survival rates, whereby individuals have the ability to search for
mates or more suitable habitat in neighbouring cells.

In order to first define our neighbourhoods for our density dependence function, it is
convenient to partially skip ahead to step 2 (building generators) and build our
dispersal generator. 

```{r, message = FALSE}
# Build the dispersal generator and calculate distance data
dispersal_gen <- DispersalGenerator$new(
  region = region,
  dispersal_max_distance = 50,
  distance_scale = 1000, # in km
  dispersal_friction = DispersalFriction$new(), # modify coastline distances
  inputs = c("dispersal_p", "dispersal_b"),
  decimals = 5)
dispersal_gen$calculate_distance_data()
head(dispersal_gen$distance_data$base) # examine
```

We will use the generator for its dispersal functionality later, but for now we will 
use its calculated distance data to define our neigbourhoods based on a 14 km range 
fromveach grid cell.

```{r, message = FALSE}
# Define neighbourhoods (of up to 9 cells) based on a 14 km range from each grid cell
# for density dependence calculations (using a dispersal generator)
distance_data <- dispersal_gen$distance_data[[1]]
nh_data <- distance_data[which(distance_data$distance_class <= 14), 2:1]
neighbourhoods <- as.list(1:795)
for (i in 1:nrow(nh_data)) {
  neighbourhoods[[nh_data$source_pop[i]]] <- c(neighbourhoods[[nh_data$source_pop[i]]],
                                               nh_data$target_pop[i])
}
neighbourhoods[1:3] # examine
```

We can now define our density dependence function, which is list-nested with our 
neighbourhoods and an Allee effect (Allee, 1931) parameter. We apply a Tasmania-wide Allee 
effect to suppress sustained low unviable populations. Additional functionality is also 
included to prevent reproduction when a neighbourhood has a single *thylacine*. We also 
define an alias to the Allee parameter so we can sample it later.

```{r, message = FALSE}
# User-defined function for Ricker logistic density dependence via neighbourhoods, with
# Allee effects; also remove fecundities if single thylacine in a neighbourhood
density_dependence <- list(
  neighbourhoods = neighbourhoods,
  allee = 25, # Tasmania-wide Allee effect parameter
  function (params) {
    
    # Apply logistic density dependence using neighbourhoods
    growth_rate_max <- params$growth_rate_max
    nh_density_abundance <- unlist(lapply(params$neighbourhoods,
                                          function (nh_indices) {
                                            sum(params$density_abundance[nh_indices])
                                          }))
    nh_carrying_capacity <- unlist(lapply(params$neighbourhoods,
                                          function (nh_indices) {
                                            sum(params$carrying_capacity[nh_indices])
                                          }))
    occupied_indices <- params$occupied_indices
    growth_rate <- growth_rate_max*(1 - (nh_density_abundance[occupied_indices]/
                                           nh_carrying_capacity[occupied_indices]))
    params$transition_array[, , occupied_indices] <-
      params$apply_multipliers(params$transition_array[, , occupied_indices],
                               params$calculate_multipliers(growth_rate))
    
    # Apply Tasmania-wide allee effect
    total_abundance <- sum(params$density_abundance)
    params$transition_array <-
      params$transition_array*total_abundance/(params$allee + total_abundance)
    
    # Remove fecundities for single thylacines
    single_indices <- which(nh_density_abundance == 1)
    params$transition_array[, , single_indices] <-
      (params$transition_array[, , single_indices]*as.vector(+(!params$fecundity_mask)))
    
    return(params$transition_array)
  }
)
density_aliases <- list(density_allee = "density_dependence$allee")
```

Note that after calculating a modified growth rate via neighbourhood abundance and 
carrying capacity for each cell, we utilize a lookup table (calculated at the time of 
simulation) so as to apply a multiplier to the stage matrix corresponding to each cell, 
thus modifying its equivalent growth rate appropriately.

##### Harvest function
Let's now define our bio-economic harvest function, which is optionally list-nested 
with harvest parameters. The total number of *thylacines* harvested at each time step
is calculated via the combination of a constant harvest rate plus a bio-economic bounty 
applied during the bounty interval (1888-1909). The bio-economic component of our 
harvest function was adapted from Bulte et al. (2003), and simulates hunting effort
based on economic return (or profit), relative to other economic alternatives. The 
number submitted for bounty is calculated via a constant fraction and is attached to
the simulator results. The total harvest is then distributed across IBRA bioregions 
based on *thylacine* bioregion densities. We define aliases for the harvest/bounty 
parameters so we can sample them later.

```{r, message = FALSE}
# Harvest bounty (economic) model user-defined function adapted from Bulte et al. (2003).
harvest <- list(
  
  # Function parameters (passed to function in params list)
  rate = 0.05,       # harvest rate with or without bounty
  fraction = 0.75,   # harvest fraction submitted for bounty
  t1 = 1888,         # first year of bounty
  tb = 1909,         # last year of bounty
  B = c(1.6, 0.6),   # bounty/skin price in pounds, pre/post bounty
  w = 3.5,           # opportunity cost in pounds per year
  E0 = 25,           # effort in 1888 (no. hunters)
  q = 0.002,         # catchability coefficient
  v1 = 0.02,         # entry rate
  v2 = 0.5,          # exit rate
  ibra_indices = ibra_indices, # bioregion cell (row) indices
  ibra_cells = ibra_cells,     # number of cells in bioregions
  
  # Function definition
  bounty_function = function(params) {
    
    # Unpack parameters (used at every time step)
    rate <- params$rate; fraction <- params$fraction; t1 <- params$t1; tb <- params$tb
    B <- params$B; w <- params$w; q = params$q; v1 <- params$v1; v2 <- params$v2
    ibra_indices <- params$ibra_indices; ibra_cells <- params$ibra_cells
    ibra_number <- length(ibra_cells); stages <- params$stages
    populations <- params$populations; simulator <- params$simulator
    tm <- params$tm; x <- params$stage_abundance
    
    # Initialise (first time step only)
    if (tm == 1) { # attach variables and access results via simulator reference object
      simulator$attached$E <- params$E0 # current bounty effort
      simulator$attached$vi <- v1 # current bounty rate
      simulator$results$bounty <- array(0, c(ibra_number, params$time_steps))
    }
    
    # Access persistent parameters via simulator reference object
    E <- simulator$attached$E
    vi <- simulator$attached$vi
    
    # Next year's hunting effort and entry/exit rates based on this year's profit
    h <- max(0, round((rate + q*E)*sum(x))) # harvest
    b <- round(h*fraction*((tm + t1 - 1) <= tb)) # bounty submitted
    profit <- round(B[((tm + t1 - 1) > tb) + 1]*b + B[2]*(h - b) - w*E, 1)
    simulator$attached$E <-  max(0, round(E + vi*profit))
    simulator$attached$vi <- c(v1, v2)[(profit < 0) + 1]
    
    # Distribute harvest and bounty across bioregions based on each IBRA density
    staged_indices <- array(1:(stages*populations), c(stages, populations))
    rep_indices <- unlist(apply(matrix(staged_indices[, unlist(ibra_indices)]), 1,
                                function(i) rep(i, x[i])))
    distributed_h <- array(0, c(stages, populations))
    if (length(rep_indices) && h > 0) {
      ibra_x <- unlist(lapply(ibra_indices, function(indices) sum(x[, indices])))
      rep_ibra <- unlist(apply(matrix(1:ibra_number), 1, function(i) rep(i, ibra_x[i])))
      rep_prob <- 1/ibra_cells[rep_ibra]
      h_indices <- sample(1:length(rep_indices), min(h, sum(x)), prob = rep_prob)
      if (b > 0) {
        b_indices <- h_indices[sample(1:length(h_indices), b)]
        simulator$results$bounty[, tm] <- tabulate(rep_ibra[b_indices], 
                                                   nbins = ibra_number)
      }
      for (i in rep_indices[h_indices]) distributed_h[i] <- distributed_h[i] + 1
    }
    
    # Return abundance
    return(x - distributed_h)
  }
)
harvest_aliases <- list(harvest_rate = "harvest$rate", 
                        harvest_fraction = "harvest$fraction",
                        harvest_w = "harvest$w", harvest_E0 = "harvest$E0",
                        harvest_q = "harvest$q", harvest_v1 = "harvest$v1",
                        harvest_v2 = "harvest$v2")
```

##### Template model
Finally, we can build our template model with these user-defined functions and their 
associated parameters, as well as other fixed model parameters.

```{r, message = FALSE}
# Population (simulation) model template for fixed parameters
model_template <- PopulationModel$new(
  region = region,
  time_steps = 80, # years (1888-1967)
  populations = region$region_cells, # 795
  # initial_abundance : generated
  # stage_matrix: generated
  fecundity_max = 2,
  demographic_stochasticity = TRUE,
  # carrying_capacity : generated
  density_dependence = density_dependence, # user-defined
  harvest = harvest, # user-defined
  # dispersal : generated
  dispersal_target_k = 0.5,
  dispersal_target_n = list(threshold = 4, cutoff = 8),
  simulation_order = c("results", "harvest", "transition", "dispersal"),
  results_selection = c("abundance", "harvested"),
  attribute_aliases = c(density_aliases, harvest_aliases))
```

Note the use of thresholds/cutoffs for dispersal target carrying capacities and 
abundances. The former suppress dispersal to cells with near-zero suitability, 
whereas the latter prevent model *thylacines* from overcrowding cells. When overridden,
the simulation order may allow the initial abundance to be included in the results.
Also note the commented placeholders for model parameters that will be sampled or 
generated.

### Step 2: Build generators for dynamically generating model parameters
Here we build a generator for combined model initial abundance and carrying capacity,
as well as a generator for generating a stage matrix for each sampled model based on 
sampled growth rate. We will test our generators, including our pre-built dispersal 
generator (from part 1), by generating some example outputs.

##### Initial habitat suitability
Firstly, our initial abundance and carrying capacity generator utilizes the habitat 
suitability for our study region. The initial habitat suitability was derived from a 
species distribution model (SDM) for the *thylacine* ...
The initial habitat suitability *raster* has also been included with the *poems*
package.

```{r, message = FALSE, fig.align = "center", fig.width = 4, fig.height = 4}
# Initial thylacine habitat suitability
hs_raster <- poems::thylacine_hs_raster
raster::plot(hs_raster, main = "Initial thylacine habitat suitability", colNA = "blue",
             xlab = "Longitude (degrees)", ylab = "Latitude (degrees)")
```

##### Habitat decline
Bulte et al. (2003) estimated a 3% per annum Tasmania-wide decline in *thylacine* 
habitat suitability due to human land use. To approximate spatial differences in 
decline, we will approximate the decline in *thylacine* habitat suitability by applying 
a constant annual decline to all IBRA bioregions except Tasmanian West (5) and Central 
Highlands (8), which have mostly retained natural ecosystems.

##### Initial abundance and carrying capacity generator
We will utilize *Generator* class functionality for creating user-defined (template) 
functions to generate initial abundance and carrying capacity (outputs). The functions 
will use the initial habitat suitability and spatial distribution of habitat decline, 
along with sampled values (inputs) for initial carrying capacity, percentage decline 
(in 7/9 IBRA bioregions), and the fraction of capacity for initial abundance (phi).

```{r, message = FALSE}
# Build a carrying capacity generator model based on habitat suitability and sampled
# initial capacity, initial fraction (phi), & decline rate per year in selected
# bioregions.
capacity_gen <- Generator$new(
  description = "capacity",
  time_steps = 80, # years (1888-1967)
  initial_hs = hs_raster[region$region_indices],
  decline_indices = which(!ibra_raster[region$region_indices] %in% c(5, 8)),
  inputs = c("k_init", "k_decline", "k_phi"),
  outputs = c("initial_abundance", "carrying_capacity"),
  generative_requirements =  list(initial_abundance = "function",
                                  carrying_capacity = "function"))
capacity_gen$add_function_template(
  "initial_abundance",
  function_def = function (params) {
    distr_k <- round(params$initial_hs/sum(params$initial_hs)*params$k_init)
    a_init <- round(params$k_init*params$k_phi) # total initial
    distr_a <- array(0, length(distr_k))
    rep_indices <- unlist(apply(matrix(1:length(distr_k)), 1,
                                function(i) rep(i, distr_k[i])))
    sample_indices <- rep_indices[sample(1:length(rep_indices),
                                         min(a_init, length(rep_indices)))]
    for (i in sample_indices) distr_a[i] <- distr_a[i] + 1
    return(distr_a)
  },
  call_params = c("initial_hs", "k_init", "k_phi"))
capacity_gen$add_function_template(
  "carrying_capacity",
  function_def = function (params) {
    distr_k <- params$initial_hs/sum(params$initial_hs)*params$k_init
    decline_matrix <- array(1, c(length(distr_k), params$time_steps))
    decline_matrix[params$decline_indices,] <-
      matrix((1 - params$k_decline)^(0:(params$time_steps - 1)),
             nrow = length(params$decline_indices), ncol = params$time_steps,
             byrow = TRUE)
    return(distr_k*decline_matrix)
  },
  call_params = c("initial_hs", "time_steps", "decline_indices",
                  "k_init", "k_decline"))
```

We can test our generator with some example (mid-value) sample inputs and
examine plots of the output initial abundance and carrying capacity (final).

```{r, message = FALSE, fig.align = "center", fig.width = 4, fig.height = 4}
# Generate example initial abundance and declining carrying capacity time-series
generated_k <- capacity_gen$generate(input_values = list(k_init = 2800,
                                                         k_decline = 0.04,
                                                         k_phi = 0.8))
example_initial_abundance <- generated_k$initial_abundance
example_carrying_capacity <- generated_k$carrying_capacity

# Plot the example initial abundance
example_initial_n_raster <- region$region_raster
example_initial_n_raster[region$region_indices] <- example_initial_abundance
raster::plot(example_initial_n_raster, main = "Example initial thylacines", 
             colNA = "blue", xlab = "Longitude (degrees)", ylab = "Latitude (degrees)")

# Plot the example final carrying capacity
example_final_raster <- region$region_raster
example_final_raster[region$region_indices] <- example_carrying_capacity[, 80]
raster::plot(example_final_raster, main = "Final thylacine carrying capacity", 
             colNA = "blue",  xlab = "Longitude (degrees)", ylab = "Latitude (degrees)", 
             zlim = c(0, 8))
```

##### Stage matrix generator
Our stage matrix generator adjusts our original stage matrix so that its
equivalent (simple) growth rate (*lambda* - 1) is that of a sampled input rate.

```{r, message = FALSE}
# Build a stage matrix generator based on sampled growth rate
stage_matrix_gen <- Generator$new(
  description = "stage matrix",
  base_matrix = matrix(c(0.00, 0.57, 1.17,
                         0.50, 0.00, 0.00,
                         0.00, 0.80, 0.80), nrow = 3, ncol = 3, byrow = TRUE),
  inputs = c("growth_r"),
  outputs = c("stage_matrix"),
  generative_requirements = list(stage_matrix = "function"))
stage_matrix_gen$add_function_template(
  "stage_matrix",
  function_def = function (params) {
    return(params$base_matrix*(1 + params$growth_r)/
             Re((eigen(params$base_matrix)$values)[1]))
  },
  call_params = c("base_matrix", "growth_r"))
```

We can test our generator with an example (mid-value) sample input growth rate of 0.25
(*lambda* = 1.25).

```{r, message = FALSE}
# Generate sampled stage matrix for growth rate: lambda = 1.25
gen_stage_m <- stage_matrix_gen$generate(input_values = list(growth_r = 0.25))
gen_stage_m # examine
```

##### Dispersal generator
We already built our dispersal generator in step 1, so as to use it to calculate 
neigbourhood distances for density dependence. We will now use it to generate some
example dispersal data.

```{r, message = FALSE}
# Generate sampled dispersals for p = 0.5, b = 7 (km)
sample_dispersal_data <- dispersal_gen$generate(
  input_values = list(dispersal_p = 0.5, dispersal_b = 7))$dispersal_data
head(sample_dispersal_data[[1]]) # examine
```

### Example model run
Before proceeding to step 3 to setup multiple model simulations, let's run our model 
with its fixed parameter values, those initially set in our user-defined density 
dependence and harvest functions, along with our generated example initial abundance, 
carrying capacity, stage matrix, and dispersal data. We will do this by cloning our 
model template and setting our example parameters before running the population 
simulator.

```{r, message = FALSE, fig.align = "center", fig.width = 6, fig.height = 4}
# Run the extended model with example parameters
model <- model_template$clone()
model$set_attributes(initial_abundance = example_initial_abundance,
                     carrying_capacity = example_carrying_capacity,
                     stage_matrix = gen_stage_m$stage_matrix,
                     dispersal = sample_dispersal_data)
results <- population_simulator(model) # run poems simulator

# Plot the total abundance and number harvested
plot(x = 1888:1967, y = results$all$abundance, xlab = "Year",
     ylab = "Number of thylacines", main = "Thylacine example extended model run",
     ylim = c(0, 2500), type = "l", col = "green", lwd = 2)
lines(x = 1888:1967, y = results$all$harvested, lty = 1, col = "red", lwd = 2)
legend("topright", legend = c("Population size", "Simulated harvest"),
       col = c("green", "red"), lty = c(1, 1), lwd = 2, cex = 0.8)
```

### Step 3: Sample model and generator parameters for each simulation
In order to explore the model parameter space to find the best models, we will now 
generate 10,000 Latin hypercube samples of model and generator parameters using the 
*LatinHypercubeSampler* class. We'll sample each parameter from uniform distributions
across parameter ranges derived from Bulte et al. (2003), and via model trial runs.

```{r, message = FALSE}
# Create a LHS object
lhs_gen <- LatinHypercubeSampler$new()

# Set capacity and growth parameters (as per Bulte et al., 2003)
lhs_gen$set_uniform_parameter("k_init", lower = 2100, upper = 3500, decimals = 0)
lhs_gen$set_uniform_parameter("k_decline", lower = 0.03, upper = 0.05, decimals = 3)
lhs_gen$set_uniform_parameter("k_phi", lower = 0.6, upper = 1.0, decimals = 2)
lhs_gen$set_uniform_parameter("growth_r", lower = 0.1875, upper = 0.3125, decimals = 2)

# Set density dependence allee effect parameter
lhs_gen$set_uniform_parameter("density_allee", lower = 0, upper = 50, decimals = 1)

# Set bio-economic harvest parameters (as per Bulte et al., 2003)
lhs_gen$set_uniform_parameter("harvest_rate", lower = 0, upper = 0.1, decimals = 3)
lhs_gen$set_uniform_parameter("harvest_fraction", lower = 0.5, upper = 1.0, 
                              decimals = 2)
lhs_gen$set_uniform_parameter("harvest_w", lower = 2.625, upper = 4.375, decimals = 1)
lhs_gen$set_uniform_parameter("harvest_E0", lower = 18.75, upper = 31.25, decimals = 0)
lhs_gen$set_uniform_parameter("harvest_q", lower = 0, upper = 0.004, decimals = 4)
lhs_gen$set_uniform_parameter("harvest_v1", lower = 0.015, upper = 0.025, decimals = 3)
lhs_gen$set_uniform_parameter("harvest_v2", lower = 0.375, upper = 0.625, decimals = 3)

# Set new spatial parameters for dispersal
lhs_gen$set_uniform_parameter("dispersal_p", lower = 0.3, upper = 0.7, decimals = 2)
lhs_gen$set_uniform_parameter("dispersal_b", lower = 4, upper = 10, decimals = 1)

# Generate samples
sample_data <- lhs_gen$generate_samples(number = SAMPLES, random_seed = 123)
head(sample_data) # examine
```

### Step 4: Build a simulation manager to run each simulation
We will now setup a *SimulationManager* class to manage the simulation of each set 
(or row) of sampled parameters. In demonstration mode we will only run the simulations
for the first two samples. The *poems* package provides example simulation summary data
for all 10,000 samples (which is used in our model ensemble selection and validation).

```{r, message = FALSE}
# Build the simulation manager
sim_manager <- SimulationManager$new(
  sample_data = sample_data,
  model_template = model_template,
  generators = list(capacity_gen, stage_matrix_gen, dispersal_gen),
  parallel_cores = PARALLEL_CORES,
  results_dir = OUTPUT_DIR)

# Run the simulations
if (DEMONSTRATION) {
  sim_manager$sample_data <- sample_data[1:2,]
}
run_output <- sim_manager$run()
run_output$summary
if (DEMONSTRATION) {
  dir(OUTPUT_DIR, "*.RData") # includes 2 result files
}
dir(OUTPUT_DIR, "*.txt") # plus simulation log
```

Note that the output directory contains a R-data result files for each sample simulation
and a simulation log file.

### Step 5: Build a results manager to generate summary results (metrics)
We will now collate summary result metrics for each of our simulations using the 
*ResultsManager* class. Here we will generate [three|four] metrics:
1. Regression slopes of total bounty submitted over three intervals.
1. [Total bounty submitted]
1. Estimated IBRA bioregion extirpation dates.
1. Estimated Tasmania-wide extinction date.
The metrics (and any desired summary matrices) are calculated via user-defined functions
operating on, or direct attributes of, *PopulationResults* class objects.

##### Using the *PopulationResults* class
To setup and test our summary metric functions, we can load the results from our example
simulation run into a *PopulationResults* class object. A time-series of IBRA bioregion 
bounty values are attached to our results via our harvest function. This can be used to 
calculate the total bounty and regression slopes for specified intervals. To obtain a 
time-series of bioregion abundance values, we can include the bioregion cell indices in
our result class object (as an attachment). We can then use this to calculate a 
time-series of abundance for each bioregion, and thus calculate extirpation times for 
each bioregion. We will use *PopulationResults* functionality for calculating 
population (cell) abundance slopes (trends) and extirpations via result object cloning.
Our clones will instead be initialized with the bounty or bioregion abundance values. 
The Tasmania-wide extinction time is directly available from the results object.

```{r, message = FALSE}
# Load our results (list) into a PopulationResults object
p_results <- PopulationResults$new(results = results,
                                   ibra_indices = ibra_indices)

# Summary metrics for IBRA bioregions and Tasmania-wide extinction
ibra_bounty <- p_results$get_attribute("bounty") # saved in harvest function
sum(ibra_bounty) # total bounty
ibra_bounty_clone <- p_results$new_clone(results = list(abundance = ibra_bounty),
                                         trend_interval = (1888:1894) - 1887)
ibra_bounty_clone$all$abundance_trend # 1888-1894 total bounty slope
ibra_abundance <- t(array(unlist(lapply(p_results$get_attribute("ibra_indices"),
                                        function (indices) {
                                          colSums(p_results$abundance[indices,])
                                        })), c(80, 9)))
ibra_abundance_clone <- p_results$new_clone(results = list(abundance = ibra_abundance))
(1888:1967)[ibra_abundance_clone$extirpation] # IBRA extirpation
(1888:1967)[p_results$all$extirpation] # total extirpation/extinction
```

##### Generating summary metrics and matrices
Once we're happy with how to derive our summary metrics (and matrices) via the 
*PopulationResults* class, we can setup our results manager to generate the metrics 
and matrix (rows) for each sample simulation results (file). Note that passing the 
simulation manager when initializing the results manager copies the previous setup 
(sample data, output directory, etc.). 

Our bounty regression slope and IBRA bioregion extirpation metrics may be combined into 
single metrics by calculating the square root of the mean square error (RMSE) of the 
simulated metrics from known or derived target values for each interval or bioregion. 
Thus our targets for each of these RMSE metrics (in step 6) will be zero. We can 
calculate these combined (RMSE) metrics using our results manager by including (or 
attaching) the target values to our results object. However, if we wish to retain 
flexibility in how we combine our individual metrics, or deal with *NA* values (e.g. 
no extirpation), in our validation and ensemble selection (in step 6), we can 
alternatively store our metrics for each slope interval or bioregion in generated 
matrix rows and combine the values later. Here we will demonstrate both approaches, 
although the matrix approach requires more disk space.

In demonstration mode, we will again only generate metrics for the first two samples.
We will load pre-generated example summaries for all 10,000 sample simulations, provided 
with the *poems* package prior to our validation and ensemble selection (in step 6).

```{r, message = FALSE}
# Set targets for our summary metrics (used to calculate combined metric errors)
slope_intervals <- c("1888-1894", "1895-1901", "1902-1909")
targets <- list(
  bounty_slope = array(c(2.36, 3.25, -17.71), dimnames = list(slope_intervals)),
  total_bounty = 2041,
  ibra_extirpation = array(c(1907, 1929, 1919, 1922, 1935, 1937, 1937, 1932, 1937),
                           dimnames = list(ibra_data$abbr)),
  total_extinction = c(1931, 1937) # CI
)

# Create a results manager for summary metrics and matrices
results_manager <- ResultsManager$new(
  simulation_manager = sim_manager,
  simulation_results = PopulationResults$new(ibra_indices = ibra_indices, # attachments
                                             targets = targets, 
                                             extirp_NA_replace = 1968), 
  result_attachment_functions = list( # attached for multiple use
    bounty_slope = function(results) { # via results object cloning
      bounty_slope <- array(NA, 3)
      ibra_bounty <- results$get_attribute("bounty") # saved in harvest function
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty),
                                             trend_interval = (1888:1894) - 1887)
      bounty_slope[1] <- ibra_bounty_clone$all$abundance_trend
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty),
                                             trend_interval = (1895:1901) - 1887)
      bounty_slope[2] <- ibra_bounty_clone$all$abundance_trend
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty),
                                             trend_interval = (1902:1909) - 1887)
      bounty_slope[3] <- ibra_bounty_clone$all$abundance_trend
      bounty_slope
    },
    ibra_extirpation = function(results) { # via results object cloning
      ibra_abundance_clone <- results$new_clone(results = list(
        abundance = t(array(unlist(lapply(results$get_attribute("ibra_indices"),
                                          function (indices) {
                                            colSums(results$abundance[indices,])
                                          })), c(80, 9)))))
      (1888:1967)[ibra_abundance_clone$extirpation]
    }),
  summary_metrics = c("bounty_slope_error", "total_bounty", 
                      "ibra_extirpation_error", "total_extinction"),
  summary_matrices = c("abundance", "bounty", "bounty_slope", "ibra_extirpation"),
  summary_functions = list(
    # Summary metrics
    bounty_slope_error = function(results) { # RMSE
      sqrt(mean((results$get_attribute("targets")$bounty_slope - 
                   results$get_attribute("bounty_slope"))^2))
    },
    total_bounty = function(results) {
      sum(results$get_attribute("bounty"))
    },
    ibra_extirpation_error = function(results) { # RMSE with NAs replaced
      ibra_extirpation <- results$get_attribute("ibra_extirpation")
      ibra_extirpation[is.na(ibra_extirpation)] <-
        results$get_attribute("extirp_NA_replace")
      sqrt(mean((results$get_attribute("targets")$ibra_extirpation - 
                   ibra_extirpation)^2))
    },
    total_extinction = function(results) {
      (1888:1967)[results$all$extirpation]
    },
    # Summary matrices
    abundance = "all$abundance", # abundance and bounty for later use
    bounty = function(results) {
      colSums(results$get_attribute("bounty"))
    },
    bounty_slope = function(results) { # calculate RMSE later
      results$get_attribute("bounty_slope")
    },
    ibra_extirpation = function(results) { # calculate RMSE later
      results$get_attribute("ibra_extirpation")
    }),
  parallel_cores = PARALLEL_CORES)

# Generate the summary metrics and matrices
gen_output <- results_manager$generate()
gen_output$summary
dir(OUTPUT_DIR, "*.txt") # plus generation log
summary_metric_data <- results_manager$summary_metric_data
summary_matrix_list <- results_manager$summary_matrix_list
head(summary_metric_data) # examine
lapply(summary_matrix_list, dim) # dimensions
head(summary_matrix_list$bounty_slope) # examine
head(summary_matrix_list$ibra_extirpation) # examine

```

Note that the summary matrix list collates the specified result for each simulation 
on a single row of each matrix. Thus the columns in the abundance and bounty matrices
represent the totals at each of the 80 simulation time steps. Likewise, the columns in
the bounty slope matrix represent regression slopes for each of the three time 
intervals, and the IBRA extirpation matrix has a column for each of our nine 
bioregions.

##### Summary metric refinement
We can now collate and refine the summary metrics that we wish to utilize in our 
validation and ensemble model selection (in step 6). Although we have already calculated
RMSE metrics for our bounty regression slopes and IBRA extirpation dates, we could
refine these by utilizing their uncombined values in the corresponding matrices. Here
we will reproduce these metrics for demonstration purposes. We will also calculate the 
error from the confidence interval (CI) for our simulated total extinction dates.

```{r, message = FALSE}
# Demonstrate calculating RMSE metrics from matrices 
if (DEMONSTRATION) { # Calculate RMSE for bounty slopes
  bounty_slope_error2 <- sqrt(rowMeans((summary_matrix_list$bounty_slope - 
                                          matrix(targets$bounty_slope, nrow = 2, 
                                                 ncol = 3, byrow = TRUE))^2))
  
  cbind(bounty_slope_error = summary_metric_data$bounty_slope_error, 
        bounty_slope_error2) # examine
}
if (DEMONSTRATION) { # Calculate RMSE for IBRA extirpation
  ibra_extirpation <- summary_matrix_list$ibra_extirpation
  ibra_extirpation[is.na(ibra_extirpation)] <- 1968
  ibra_extirpation_error2 <- sqrt(rowMeans((ibra_extirpation - 
                                              matrix(targets$ibra_extirpation, nrow = 2, 
                                                     ncol = 9, byrow = TRUE))^2))
  cbind(ibra_extirpation_error = summary_metric_data$ibra_extirpation_error, 
        ibra_extirpation_error2) # examine
}

# Load full example metrics
if (DEMONSTRATION) { 
  summary_metric_data <- poems::thylacine_example_metrics
  dim(summary_metric_data) # dimensions
}

# Calculate the error from the CI of total extinction
extinct <- summary_metric_data$total_extinction
target_CI <- targets$total_extinction
summary_metric_data$total_extinction_error <-  
  ((extinct < target_CI[1])*(extinct - target_CI[1]) + 
     (extinct > target_CI[2])*(extinct - target_CI[2]))
head(summary_metric_data) # examine
```

Here we could have also replaced *NA* values when calculating the error of the total
extinction date (from the target CI), however we will defer this so as to demonstrate
*NA* replacement functionality in the validator in the next step.

### Step 6: Build a validator to select a model ensemble
We will now validate and select our model ensemble via the *Validator* class, which by
default utilizes an approximate Bayesian computation (ABC) approach (Beaumont, Zhang, 
& Balding, 2002) provided by the *abc* library (Csillery et al., 2015). We will use the 
default configuration to select the best 100 models (via a *tolerance* of 0.01). Our
targets for selecting the best models will be zero for our RMSE metrics (bounty slope 
and IBRA extirpation) and error metric for total extinction (CI), and 2041 for our 
total bounty submission metric. Note that for models where our simulated *thylacine* 
persist until the end of the simulation (1967), the extinction (CI error) value will be 
*NA*. Since the *abc* function requires finite values only, we will use the 
*non_finite_replacements* attribute of the validator to replace these *NA* values with 
the CI error corresponding to 1968.

Note that the validator generates diagnostics (as per the *abc* documentation) as a PDF
file in the configured output directory. We may wish to configure this directory, as 
locating the default output directory generated via *tempdir()* can be tedious.

```{r, message = FALSE}
# Create a validator for selecting the 'best' example models
validator <- Validator$new(
  simulation_parameters = sample_data,
  simulation_summary_metrics = summary_metric_data[-c(1, 5)],
  observed_metric_targets = c(bounty_slope_error = 0, total_bounty = 2041, 
                              ibra_extirpation_error = 0, total_extinction_error = 0),
  non_finite_replacements = list(total_extinction_error = function(x) {
    (1968 - targets$total_extinction[2])}),
  output_dir = OUTPUT_DIR)
suppressWarnings(validator$run(tolerance = 0.01,
                               output_diagnostics = TRUE))
dir(OUTPUT_DIR, "*.pdf") # plus validation diagnostics (see abc library documentation)
head(validator$selected_simulations) # examine
dim(validator$selected_simulations) # dimensions
selected_indices <- validator$selected_simulations$index
selected_weights <- validator$selected_simulations$weight
```

Note that each selected model (via its index in the sample data frame) have a 
corresponding weight value, which is indicative of the congruence between each model's 
summary metrics and the corresponding target patterns.

We can visualize the congruence of the selected models with the targets via simple 
plots. Note that simulations that persist are represented via extirpation date: 1968.

When in demonstration mode, we will load pre-generated example matrices, provided with 
the *poems* package, containing bounty slope and IBRA bioregion extirpations for all 
10,000 sample simulations, as well as total abundance and bounty time-series for our 
100 selected models only (due to vignette space limitations).

```{r, message = FALSE, fig.align = "center", fig.width = 6, fig.height = 6}
if (DEMONSTRATION) { # load pre-generated example matrices
  summary_matrix_list <- thylacine_example_matrices #### poems::
}

# Plot the simulation, targets, and selected metrics for extinction and bounty
extinction_time <- summary_metric_data$total_extinction
extinction_time[which(is.na(extinction_time))] <- 1968
total_bounty <- summary_metric_data$total_bounty
graphics::plot(x = extinction_time, y = total_bounty,
               main = "Thylacine model validation (plot 1)",
               xlab = "Extinction time (year)", ylab = "Total bounty", col = "gray")
graphics::points(x = extinction_time[selected_indices],
                 y = total_bounty[selected_indices],
                 col = "blue", pch = 3)
graphics::lines(x = targets$total_extinction, y = rep(2041, 2), col = "red", lwd = 2)
graphics::legend("topleft", legend = c("Summary metrics", "Targets (CI)", "Selected"),
                 col = c("gray", "red", "blue"), pch = c(1, NA, 3), lwd = c(NA, 2, NA),
                 cex = 0.8)

# Plot the simulation, targets, and selected metrics for bounty slopes
bounty_slope <- summary_matrix_list$bounty_slope
graphics::plot(x = rep(1:3, each = 10000), y = bounty_slope,
               main = "Thylacine model validation (plot 2)",
               xlab = "Slope interval (years)", ylab = "Bounty regression slope", 
               xaxt = "n", col = "gray", ylim = c(-100, 50))
graphics::axis(1, at = 1:3, labels = slope_intervals)
graphics::points(x = rep(1:3, each = 100), y = bounty_slope[selected_indices,],
                 col = "blue", pch = 3)
graphics::points(x = 1:3, y = targets$bounty_slope,
                 col = "red", pch = 4)
graphics::legend("bottomright", col = c("gray", "red", "blue"), pch = c(1, 4, 3),
                 legend = c("Summary metrics", "Targets (CI)", "Selected"), cex = 0.8)

# Plot the simulation, targets, and selected metrics for IBRA extirpation
ibra_extirpation <- summary_matrix_list$ibra_extirpation
graphics::plot(x = ibra_extirpation, y = rep(1:9, each = 10000),
               main = "Thylacine model validation (plot 3)",
               xlab = "Extirpation time (year)", ylab = "IBRA bioregion", 
               yaxt = "n", col = "gray", ylim = c(-0.5, 9))
graphics::axis(2, at = 1:9, labels = ibra_data$abbr)
graphics::points(x = ibra_extirpation[selected_indices,], y = rep(1:9, each = 100),
                 col = "blue", pch = 3)
graphics::points(x = targets$ibra_extirpation, y = 1:9,
                 col = "red", pch = 4)
graphics::legend("bottomright", col = c("gray", "red", "blue"), pch = c(1, 4, 3),
                 legend = c("Summary metrics", "Targets (CI)", "Selected"), cex = 0.8)
```

These plots can show us how well our validator has matched our individual (uncombined) 
metric targets. From the diagnostic output (PDF file in our output directory), we can 
also examine the posterior distributions of our 100 selected model parameters (in red) 
relative to those of all 10,000 simulations (in black), and their prior distributions 
(dashed line). This can give us insight into the influence of each model parameter has
had on our model selection. From these diagnostics and plots we can analyse and assess
the adequacy of our model and/or summary metrics. We may choose to refine our model 
parameter ranges or our summary metrics. We may also choose to simulate a more 
extensive parameter space, or revisit our model structure. We may also wish to examine 
the role (demographic) stochasticity has played in our model selection.

##### Impacts of stochasticity
We will now re-run each of our selected 100 models ten times, so as to examine the 
impact of demographic stochasticity on our summary metrics. Note that in demonstration 
mode, we will only run the first two re-run simulations, then load example re-run 
summary metrics provided by the *poems* package. Note that in order to not to override
existing results files we can either change our output directory, or alternatively, as
we do here, change the naming of the output files via the *results_filename_attributes* 
attribute of the simulation and results managers.

#### HERE ####

#' -----10--------20--------30--------40--------50--------60--------70--------80--------90

```{r, message = FALSE}
# Run replicates of 10 for each selected model
sample_data_rerun <- cbind(sample = 1:nrow(sample_data), sample_data)
sample_data_rerun <- cbind(sample_data_rerun[rep(selected_indices, each = 10),],
                           rerun = rep(1:10, length(selected_indices)))
head(sample_data_rerun) # examine
if (DEMONSTRATION) {
  sim_manager$sample_data <- sample_data_rerun[1:2,]
} else {
  sim_manager$sample_data <- sample_data_rerun
}
sim_manager$results_filename_attributes <- c("sample", "rerun")
run_output <- sim_manager$run()
run_output$summary
if (DEMONSTRATION) {
  dir(OUTPUT_DIR, "*.RData") # includes 2 new result files
}

# Collate summary metrics for re-runs
if (DEMONSTRATION) {
  results_manager$sample_data <- sample_data_rerun[1:2,]
} else {
  results_manager$sample_data <- sample_data_rerun
}
results_manager$results_filename_attributes <- c("sample", "rerun")
gen_output <- results_manager$generate()
gen_output$summary
if (DEMONSTRATION) {
  results_manager$summary_metric_data # examine demo
}
if (DEMONSTRATION) { # load full example metrics
  summary_metric_data_rerun <- poems::thylacine_example_metrics_p1_rerun
} else {
  summary_metric_data_rerun <- results_manager$summary_metric_data
}
head(summary_metric_data_rerun) # examine
dim(summary_metric_data_rerun) # dimensions
```

Note that the output directory contains new R-data result files for each sample rerun
simulation, named via a unique combination of sample data frame attributes.

Now we can re-plot the metrics for all, selected, and re-run models to visualize the
impact of stochasticity.

```{r, message = FALSE, fig.align = "center", fig.width = 6, fig.height = 6}
# Plot with replicates
graphics::plot(x = extinction_time, y = total_bounty,
               main = "Thylacine model validation",
               xlab = "Extinction time (year)", ylab = "Total bounty")
extinction_time_r <- summary_metric_data_rerun$extinction_time + 1887
extinction_time_r[which(is.na(extinction_time_r))] <- 1968
total_bounty_r <- summary_metric_data_rerun$total_bounty
graphics::points(x = extinction_time_r, y = total_bounty_r,
                 col = "gold3", pch = 3)
graphics::points(x = extinction_time[selected_indices],
                 y = total_bounty[selected_indices],
                 col = "blue", pch = 3)
graphics::points(x = 1934, y = 2041, col = "red", pch = 4)
graphics::legend("topleft", legend = c("Summary metrics", "Targets", "Selected", "Replicates"),
                 col = c(1, "red", "blue", "gold3"), pch = c(1, 4, 3, 3), cex = 0.8)
```

We can also compare the distributions of our metrics for all, selected, and re-run 
models to better assess the impact of stochasticity.

```{r, message = FALSE, fig.align = "center", fig.width = 6, fig.height = 4}
# Total bounty
hist(total_bounty, breaks = 40, main = "Thylacine bounty", xlab = "Total bounty",
     col = "grey")
hist(rep(total_bounty_r, 2), breaks = 10, col = "gold3", add = TRUE)
hist(rep(total_bounty[selected_indices], 5), breaks = 6, col = "blue", add = TRUE)
lines(x = rep(2041, 2), y = c(0, 1000), col = "red", lwd = 2)
legend("topleft", c("All", "Target", "Selected", "Replicates"),
       fill = c("grey", "red", "blue", "gold3"), cex = 0.8)

# Extinction time
hist(extinction_time, breaks = 40, main = "Thylacine extirpation",
     xlab = "Extinction time (year)", col = "grey")
hist(rep(extinction_time_r, 5), breaks = 30, col = "gold3", add = TRUE)
hist(rep(extinction_time[selected_indices], 10), breaks = 5, col = "blue", add = TRUE)
lines(x = rep(1934, 2), y = c(0, 5000), col = "red", lwd = 2)
legend("topleft", c("All", "Target", "Selected", "Replicates"),
       fill = c("grey", "red", "blue", "gold3"), cex = 0.8)
```

From these plots we can conclude that stochastic processes operating in our model may 
have a substantial impact on our model validation and ensemble selection, particularly
for extirpation times. We could further analyze the effects of stochasticity by 
exploring approaches for identifying which of our selected models are congruent with
our target metrics most frequently.

##### Using the model ensemble
Let's now use our model ensemble to compare our simulated bounty submitted to the
historical (time-series) records (provided with the *poems* package). Here we will use 
the selected model weights to calculate a weighted average of simulated bounty 
submitted. The bounty results were summarized as a matrix for the full 10,000 runs. In 
demonstration mode, the selected bounty time-series are again provided by the *poems* 
package.

```{r, message = FALSE, fig.align = "center", fig.width = 6, fig.height = 4}
# Compare weighted ensemble model to actual historical bounty time-series
historic_bounty <- poems::thylacine_bounty_record$total
sum(historic_bounty) # examine total
if (DEMONSTRATION) {
  selected_bounty <- poems::thylacine_example_matrices_p1$bounty
} else {
  selected_bounty <- summary_matrix_list$bounty[selected_indices,]
}
weights <- validator$selected_simulations$weight
weighted_bounty <- colSums(selected_bounty*weights/sum(weights))
sum(weighted_bounty) # examine total

# Plot the simulated and actual bounty
plot(x = 1888:1909, y = weighted_bounty[1:22], xlab = "Year",
     ylab = "Number of thylacines", main = "Thylacine bounty submitted",
     ylim = c(0, 250), type = "l", col = "blue", lwd = 2)
lines(x = 1888:1909, y = historic_bounty, lty = 1, col = "red", lwd = 2)
legend("topright", legend = c("Model ensemble bounty", "Actual bounty"),
       col = c("blue", "red"), lty = c(1, 1), lwd = 2, cex = 0.8)
```

Although our model ensemble results have a similar total number of bounty submissions 
to the actual historic total, the difference in bounty time-series suggests our simple 
harvest function, using constant harvest and bounty rates, is inadequate for modeling
the harvest response to the bounty reward. We explore utilizing a more complex harvest 
function in part 2.

## Part 2
In this part of the vignette we extend our harvest function to utilize a bio-economic
approach adapted from Bulte et al. (2003). We also formulate more complex spatially 
explicit metrics for ensemble validation and selection, utilizing known bounty values 
and derived (approximate) extirpation dates, bounty end dates, and bounty regression 
slopes, for our nine IBRA bioregions.

### Step 1 (extended): Re-build the population model
We start by re-building our model template with fixed model parameters and user-defined
functions, including our new bio-economic harvest function. We will continue to use
components of our model from part 1 that remain unchanged, including our study region, 
IBRA bioregions, and neighbourhood-based density dependence function. 

##### Bio-economic harvest function
Our new bio-economic harvest function, which is again list-nested with harvest 
parameters, replaces the constant bounty rate, applied during the bounty interval 
(1888-1909), with a function that simulates hunting effort based on economic return
(or profit), relative to other economic alternatives (see Bulte et al., 2003 for 
further details). The total harvest now becomes the sum of a constant (non-bounty)
harvest rate (as before) and the new bio-economic bounty harvest. In addition to
the bio-economic harvest component, the total harvest will now also be distributed 
across IBRA bioregions based on *thylacine* bioregion densities. Once again, we 
define aliases for the harvest/bounty parameters so we can sample them later.

```{r, message = FALSE}
# Calculate cell indices and counts for IBRA bioregions
ibra_indices <- lapply(as.list(ibra_data$index),
                       function(i) {
                         which(ibra_raster[region$region_indices] == i)
                       })
ibra_cells <- unlist(lapply(ibra_indices, length))

# Harvest bounty (economic) model user-defined function derived from Bulte et al. (2003).
harvest <- list(
  
  # Function parameters (passed to function in params list)
  rate = 0.05,       # harvest rate with or without bounty
  fraction = 0.75,   # harvest fraction submitted for bounty
  t1 = 1888,         # first year of bounty
  tb = 1909,         # last year of bounty
  B = c(1.6, 0.6),   # bounty/skin price in pounds, pre/post bounty
  w = 3.5,           # opportunity cost in pounds per year
  E0 = 25,           # effort in 1888 (no. hunters)
  q = 0.002,         # catchability coefficient ####0-0.004
  v1 = 0.02,         # entry rate
  v2 = 0.5,          # exit rate
  ibra_indices = ibra_indices, # bioregion cell (row) indices
  ibra_cells = ibra_cells,     # number of cells in bioregions
  
  # Function definition
  bounty_function = function(params) {
    
    # Unpack parameters (used at every time step)
    rate <- params$rate; fraction <- params$fraction; t1 <- params$t1; tb <- params$tb
    B <- params$B; w <- params$w; q = params$q; v1 <- params$v1; v2 <- params$v2
    ibra_indices <- params$ibra_indices; ibra_cells <- params$ibra_cells
    ibra_number <- length(ibra_cells); stages <- params$stages
    populations <- params$populations; simulator <- params$simulator
    tm <- params$tm; x <- params$stage_abundance
    
    # Initialise (first time step only)
    if (tm == 1) { # attach variables and access results via simulator reference object
      simulator$attached$E <- params$E0 # current bounty effort
      simulator$attached$vi <- v1 # current bounty rate
      simulator$results$bounty <- array(0, c(ibra_number, params$time_steps))
    }
    
    # Access persistent parameters via simulator reference object
    E <- simulator$attached$E
    vi <- simulator$attached$vi
    
    # Next year's hunting effort and entry/exit rates based on this year's profit
    h <- max(0, round((rate + q*E)*sum(x))) # harvest
    b <- round(h*fraction*((tm + t1 - 1) <= tb)) # bounty submitted
    profit <- round(B[((tm + t1 - 1) > tb) + 1]*b + B[2]*(h - b) - w*E, 1)
    simulator$attached$E <-  max(0, round(E + vi*profit))
    simulator$attached$vi <- c(v1, v2)[(profit < 0) + 1]
    
    # Distribute harvest and bounty across bioregions based on each IBRA density
    staged_indices <- array(1:(stages*populations), c(stages, populations))
    rep_indices <- unlist(apply(matrix(staged_indices[, unlist(ibra_indices)]), 1,
                                function(i) rep(i, x[i])))
    distributed_h <- array(0, c(stages, populations))
    if (length(rep_indices) && h > 0) {
      ibra_x <- unlist(lapply(ibra_indices, function(indices) sum(x[, indices])))
      rep_ibra <- unlist(apply(matrix(1:ibra_number), 1, function(i) rep(i, ibra_x[i])))
      rep_prob <- 1/ibra_cells[rep_ibra]
      h_indices <- sample(1:length(rep_indices), min(h, sum(x)), prob = rep_prob)
      if (b > 0) {
        b_indices <- h_indices[sample(1:length(h_indices), b)]
        simulator$results$bounty[, tm] <- tabulate(rep_ibra[b_indices], 
                                                   nbins = ibra_number)
      }
      for (i in rep_indices[h_indices]) distributed_h[i] <- distributed_h[i] + 1
    }
    
    # Return abundance
    return(x - distributed_h)
  }
)
harvest_aliases <- list(harvest_rate = "harvest$rate", 
                        harvest_fraction = "harvest$fraction",
                        harvest_w = "harvest$w", harvest_E0 = "harvest$E0",
                        harvest_q = "harvest$q", harvest_v1 = "harvest$v1",
                        harvest_v2 = "harvest$v2")
```

##### Template model (re-built)
Now we re-build our template model with our new user-defined harvest function. We will
also generate our stage matrix via a new generator (in the next step), and will thus
allow the maximum growth rate to be calculated via the generated stage matrix (within
the simulator). Other fixed parameters remain the same. Placeholders for sampled and
generated parameters are again indicated via comments.

```{r, message = FALSE}
# Re-built population (simulation) model template for fixed parameters
model_template <- PopulationModel$new(
  region = region,
  time_steps = 80, # years (1888-1967)
  populations = region$region_cells, # 795
  # initial_abundance : generated
  # stage_matrix: generated
  fecundity_max = 2,
  demographic_stochasticity = TRUE,
  # carrying_capacity : generated
  density_dependence = density_dependence, # user-defined
  harvest = harvest, # user-defined
  # dispersal : generated
  dispersal_target_k = 0.5,
  dispersal_target_n = list(threshold = 4, cutoff = 8),
  simulation_order = c("results", "harvest", "transition", "dispersal"),
  results_selection = c("abundance", "harvested"),
  attribute_aliases = c(density_aliases, harvest_aliases))
```

### Step 2 (extended): Build additional generators
We will continue to use our generators from part 1 for initial abundance, carrying 
capacity, and dispersal. Here we build a new generator for generating a stage matrix
for each sampled model based on sampled growth rate.

##### Stage matrix generator
Our stage matrix generator adjusts our original stage matrix so that its
equivalent (simple) growth rate (*lambda* - 1) is that of a sampled input rate.

```{r, message = FALSE}
# Build a stage matrix generator based on sampled growth rate
stage_matrix_gen <- Generator$new(
  description = "stage matrix",
  base_matrix = matrix(c(0.00, 0.57, 1.17,
                         0.50, 0.00, 0.00,
                         0.00, 0.80, 0.80), nrow = 3, ncol = 3, byrow = TRUE),
  inputs = c("growth_r"),
  outputs = c("stage_matrix"),
  generative_requirements = list(stage_matrix = "function"))
stage_matrix_gen$add_function_template(
  "stage_matrix",
  function_def = function (params) {
    return(params$base_matrix*(1 + params$growth_r)/
             Re((eigen(params$base_matrix)$values)[1]))
  },
  call_params = c("base_matrix", "growth_r"))
```

We can test our generator with an example (mid-value) sample input growth rate of 0.25
(*lambda* = 1.25).

```{r, message = FALSE}
# Generate sampled stage matrix for growth rate: lambda = 1.25
gen_stage_m <- stage_matrix_gen$generate(input_values = list(growth_r = 0.25))
gen_stage_m # examine
```

### Example extended model run
Before proceeding to our extended step 3, let's run our new model with its fixed 
parameter values, those initially set in our user-defined functions, along with our 
generated example initial abundance, carrying capacity, dispersal data, and stage 
matrix. Again, we will do this by cloning our model template and setting our example 
parameters before running the population simulator.

```{r, message = FALSE, fig.align = "center", fig.width = 6, fig.height = 4}
# Run the extended model with example parameters
model <- model_template$clone()
model$set_attributes(initial_abundance = example_initial_abundance,
                     carrying_capacity = example_carrying_capacity,
                     stage_matrix = gen_stage_m$stage_matrix,
                     dispersal = sample_dispersal_data)
results <- population_simulator(model) # run poems simulator

# Plot the total abundance and number harvested
plot(x = 1888:1967, y = results$all$abundance, xlab = "Year",
     ylab = "Number of thylacines", main = "Thylacine example extended model run",
     ylim = c(0, 2500), type = "l", col = "green", lwd = 2)
lines(x = 1888:1967, y = results$all$harvested, lty = 1, col = "red", lwd = 2)
legend("topright", legend = c("Population size", "Simulated harvest"),
       col = c("green", "red"), lty = c(1, 1), lwd = 2, cex = 0.8)
```

### Step 3 (extended): Sample model and generator parameters for each simulation
We now repeat step 3 with our extended parameter space, including our new bio-economic
harvest model and stage matrix generation parameters. Once again, the ranges of these
new parameters are also derived from Bulte et al. (2003), and via model trial runs.
We'll sample each parameter from uniform distributions utilizing the 
*LatinHypercubeSampler* class.

```{r, message = FALSE}
# Create a LHS object
lhs_gen <- LatinHypercubeSampler$new()

# Set capacity and growth parameters (as per Bulte et al., 2003)
lhs_gen$set_uniform_parameter("k_init", lower = 2100, upper = 3500, decimals = 0)
lhs_gen$set_uniform_parameter("k_decline", lower = 0.03, upper = 0.05, decimals = 3)
lhs_gen$set_uniform_parameter("k_phi", lower = 0.6, upper = 1.0, decimals = 2)
lhs_gen$set_uniform_parameter("growth_r", lower = 0.1875, upper = 0.3125, decimals = 2)

# Set density dependence allee effect parameter
lhs_gen$set_uniform_parameter("density_allee", lower = 0, upper = 50, decimals = 1)

# Set bio-economic harvest parameters (as per Bulte et al., 2003)
lhs_gen$set_uniform_parameter("harvest_rate", lower = 0, upper = 0.1, decimals = 3)
lhs_gen$set_uniform_parameter("harvest_fraction", lower = 0.5, upper = 1.0, 
                              decimals = 2)
lhs_gen$set_uniform_parameter("harvest_w", lower = 2.625, upper = 4.375, decimals = 1)
lhs_gen$set_uniform_parameter("harvest_E0", lower = 18.75, upper = 31.25, decimals = 0)
lhs_gen$set_uniform_parameter("harvest_q", lower = 0, upper = 0.004, decimals = 4)
lhs_gen$set_uniform_parameter("harvest_v1", lower = 0.015, upper = 0.025, decimals = 3)
lhs_gen$set_uniform_parameter("harvest_v2", lower = 0.375, upper = 0.625, decimals = 3)

# Set new spatial parameters for dispersal
lhs_gen$set_uniform_parameter("dispersal_p", lower = 0.3, upper = 0.7, decimals = 2)
lhs_gen$set_uniform_parameter("dispersal_b", lower = 4, upper = 10, decimals = 1)

# Generate samples
sample_data <- lhs_gen$generate_samples(number = SAMPLES, random_seed = 123)
head(sample_data) # examine
```

### Step 4 (extended): Build a simulation manager to run each simulation
We will now use a *SimulationManager* class to run our new extended model for each 
sample. Once again, in demonstration mode we will only run the simulations for the 
first two samples. The *poems* package again provides example simulation summary data
for all 10,000 samples.

```{r, message = FALSE}
# Build the simulation manager
sim_manager <- SimulationManager$new(
  sample_data = sample_data,
  model_template = model_template,
  generators = list(capacity_gen, dispersal_gen, stage_matrix_gen),
  parallel_cores = PARALLEL_CORES,
  results_dir = OUTPUT_DIR,
  results_filename_attributes = "sample_p2")

# Run the simulations
if (DEMONSTRATION) {
  sim_manager$sample_data <- sample_data[1:2,]
}
run_output <- sim_manager$run()
run_output$summary
if (DEMONSTRATION) {
  dir(OUTPUT_DIR, "*.RData") # includes 2 new result files for part 2
}
```

Note that the output directory now contains new R-data result files for our part 2 (p2)
simulations.

### Step 5 (extended): Build a results manager to generate summary results (metrics)
We will now use a *ResultsManager* class to collate summary result metrics for our part
2 simulations. For part 2 we will formulate more complex spatially explicit metrics
utilizing known bounty totals and end dates, derived bounty regression slopes, and 
estimated extirpation dates, for our nine IBRA bioregions.

##### Advanced *PopulationResults* class usage
To setup and test more complex summary metric functions, we can again load the results
from our example simulation run into a *PopulationResults* class object. Our new
harvest function already attaches a time-series of IBRA bioregion bounty values to our
results, which can be used to calculate bounty totals, end years and regression slopes
for each bioregion. To obtain a time-series of bioregion abundance values, we can
include the bioregion cell indices in our result class objects (as an attachment). We
can then use this to calculate a time-series of abundance for each bioregion, and thus
calculate extirpation times for each bioregion. We will use *PopulationResults* 
functionality for calculating population (cell) abundance extirpations and slopes 
(trends) via result object cloning. Our clones will instead be initialized with the
bounty or abundance values for each bioregion, rather than for each cell.

```{r, message = FALSE}
# Load our results (list) into a PopulationResults object
p_results <- PopulationResults$new(results = results,
                                   ibra_indices = ibra_indices)

# Summary metrics for each IBRA bioregion and Tasmania-wide total
ibra_bounty <- p_results$get_attribute("bounty") # saved in harvest function
rowSums(ibra_bounty) # IBRA bounty
sum(ibra_bounty) # total bounty
ibra_bounty_clone <- p_results$new_clone(results = list(abundance = ibra_bounty))
(1888:1967)[ibra_bounty_clone$extirpation] # IBRA bounty end
(1888:1967)[ibra_bounty_clone$all$extirpation] # total bounty end
ibra_bounty_clone$trend_interval <- (1888:1894) - 1887
ibra_bounty_clone$abundance_trend # IBRA 1888-1894 bounty slope
ibra_bounty_clone$all$abundance_trend # total 1888-1894 bounty slope
ibra_abundance <- t(array(unlist(lapply(p_results$get_attribute("ibra_indices"),
                                        function (indices) {
                                          colSums(p_results$abundance[indices,])
                                        })), c(80, 9)))
ibra_abundance_clone <- p_results$new_clone(results = list(abundance = ibra_abundance))
(1888:1967)[ibra_abundance_clone$extirpation] # IBRA extirpation
(1888:1967)[p_results$all$extirpation] # total extirpation
```

##### Generating summary metrics and matrices
We can now setup our results manager to generate the metrics and matrix (rows) for each
sample simulation results (file). Our bounty total, end year, slope, and extirpation 
metrics for each IBRA bioregion may be combined into single metrics by calculating the
square root of the mean square error (RMSE) of the simulated metrics relative to known 
or derived target values for each bioregion (as provided with the *poems* package). Thus 
our targets for each of these metrics (in step 6) will be zero. We can calculate these
combined (RMSE) metrics using our results manager by including (or attaching) the target 
values to our results object. However, if we wish to retain flexibility in how we 
combine our individual bioregion metrics in our validation and ensemble selection (in 
step 6), we can alternatively store our metrics for each of the nine bioregions in 
generated matrix rows (thus nine columns per sample row) and combine the values later. 
Here we will demonstrate both approaches, although the matrix approach requires more 
disk space. Again, in demonstration mode, we will only generate metrics and matrices 
for the first two samples, after which we will load pre-generated example summary 
metrics (and limited matrices) provided with the *poems* package.

```{r, message = FALSE}
# Set targets for our summary metrics (used to calculate combined metric errors)
slope_intervals <- c("1888-1894", "1895-1901", "1902-1909")
targets <- list(
  ibra_bounty = colSums(poems::thylacine_bounty_record[, 3:11]),
  total_bounty = sum(poems::thylacine_bounty_record$total),
  ibra_bounty_end = c(1906, 1908, 1907, 1908, 1909, 1908, 1908, 1905, 1908),
  total_bounty_end = 1909,
  ibra_bounty_slope = matrix(
    c(-0.68, -0.32,  0.57,  2.11, -0.07,  1.43, -1.04,  0.14,  0.21,
       0.32,  1.64, -0.82, -4.07, -0.18,  1.29,  1.25,  0.32,  3.50,
      -0.88, -3.30, -2.35, -3.10,  0.45, -2.81, -4.08, -0.36, -1.30),
    nrow = 3, ncol = 9, byrow = TRUE,  
    dimnames = list(slope_intervals, ibra_data$abbr)),
  total_bounty_slope = array(c(2.36, 3.25, -17.71), dimnames = list(slope_intervals)),
  ibra_extirpation = c(1907, 1929, 1919, 1922, 1935, 1937, 1937, 1932, 1937),
  total_extirpation = c(1931, 1937) # CI
)

# Create a results manager for summary metrics and matrices
results_manager <- ResultsManager$new(
  simulation_manager = sim_manager,
  simulation_results = PopulationResults$new(ibra_indices = ibra_indices,
                                             targets = targets), # attach
  result_attachment_functions = list( # attached for multiple use
    ibra_abundance = function(results) {
      t(array(unlist(lapply(results$get_attribute("ibra_indices"),
                            function (indices) {
                              colSums(results$abundance[indices,])
                            })), c(80, 9)))
    }),
  summary_metrics = c("ibra_bounty_err", "total_bounty", 
                      "ibra_bounty_end_err", "total_bounty_end", 
                      "ibra_extirpation_err", "total_extirpation"),
  summary_matrices = c("abundance", "bounty", # for later use with model ensemble
                       "ibra_bounty", "ibra_bounty_end", "ibra_bounty_slope", 
                       "total_bounty_slope", "ibra_extirpation"),
  summary_functions = list(
    # Summary metrics
    ibra_bounty_err = function(results) {
      sqrt(mean((results$get_attribute("targets")$ibra_bounty -
                   rowSums(results$get_attribute("bounty")))^2))
    },
    total_bounty = function(results) {
      sum(results$get_attribute("bounty"))
    },
    ibra_bounty_end_err = function(results) {
      ibra_bounty <- results$get_attribute("bounty") # saved in harvest function
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty))
      sqrt(mean((results$get_attribute("targets")$ibra_bounty_end -
                   (1888:1967)[ibra_bounty_clone$extirpation])^2))
    },
    total_bounty_end = function(results) {
      ibra_bounty <- results$get_attribute("bounty") # saved in harvest function
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty))
      (1888:1967)[ibra_bounty_clone$all$extirpation]
    },
    ibra_extirpation_err = function(results) {
      ibra_abundance <- results$get_attribute("ibra_abundance")
      ibra_abundance_clone <-
        results$new_clone(results = list(abundance = ibra_abundance))
      sqrt(mean((results$get_attribute("targets")$ibra_extirpation -
                   (1888:1967)[ibra_abundance_clone$extirpation])^2))
    },
    total_extirpation = "all$extirpation",
    # Summary matrices
    abundance = "all$abundance",
    bounty = function(results) {
      colSums(results$get_attribute("bounty"))
    },
    ibra_bounty = function(results) {
      rowSums(results$get_attribute("bounty"))
    },
    ibra_bounty_end = function(results) {
      ibra_bounty <- results$get_attribute("bounty") # saved in harvest function
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty))
      (1888:1967)[ibra_bounty_clone$extirpation]
    },
    ibra_bounty_slope = function(results) { # matrix flattens to single row
      ibra_bounty_slope <- NA*results$get_attribute("targets")$ibra_bounty_slope
      ibra_bounty <- results$get_attribute("bounty") # saved in harvest function
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty))
      ibra_bounty_clone$trend_interval <- (1888:1894) - 1887
      ibra_bounty_slope[1,] <- ibra_bounty_clone$abundance_trend
      ibra_bounty_clone$abundance_trend <- NULL # reset
      ibra_bounty_clone$trend_interval <- (1895:1901) - 1887
      ibra_bounty_slope[2,] <- ibra_bounty_clone$abundance_trend
      ibra_bounty_clone$abundance_trend <- NULL # reset
      ibra_bounty_clone$trend_interval <- (1902:1909) - 1887
      ibra_bounty_slope[3,] <- ibra_bounty_clone$abundance_trend
      ibra_bounty_slope
    },
    total_bounty_slope = function(results) {
      total_bounty_slope <- NA*results$get_attribute("targets")$total_bounty_slope
      ibra_bounty <- results$get_attribute("bounty") # saved in harvest function
      ibra_bounty_clone <- results$new_clone(results = list(abundance = ibra_bounty))
      ibra_bounty_clone$trend_interval <- (1888:1894) - 1887
      total_bounty_slope[1] <- ibra_bounty_clone$all$abundance_trend
      ibra_bounty_clone$all$abundance_trend <- NULL # reset
      ibra_bounty_clone$trend_interval <- (1895:1901) - 1887
      total_bounty_slope[2] <- ibra_bounty_clone$all$abundance_trend
      ibra_bounty_clone$all$abundance_trend <- NULL # reset
      ibra_bounty_clone$trend_interval <- (1902:1909) - 1887
      total_bounty_slope[3] <- ibra_bounty_clone$all$abundance_trend
      total_bounty_slope
    },
    ibra_extirpation = function(results) {
      ibra_abundance <- results$get_attribute("ibra_abundance")
      ibra_abundance_clone <- 
        results$new_clone(results = list(abundance = ibra_abundance))
      (1888:1967)[ibra_abundance_clone$extirpation]
    }),
  parallel_cores = PARALLEL_CORES)

# Generate the summary metrics and matrices
gen_output <- results_manager$generate()
gen_output$summary
summary_metric_data_p2 <- results_manager$summary_metric_data
summary_matrix_list_p2 <- results_manager$summary_matrix_list
head(summary_metric_data_p2) # examine
lapply(summary_matrix_list_p2, dim) # dimensions
```

Note that the calculated regression slope of bounty submitted for each IBRA bioregion
across the three time periods is a flattened matrix in each sample row of its summary 
matrix list.

##### Additional summary metric combinations via matrices
Since we retained our bounty total, end year, slope, and extirpation metrics for each 
IBRA bioregion, we can now combine them in a variety of ways to explore which metric
combinations to use with our validation and model ensemble selection in step 6. Here 
we could calculate as many combined metrics as we may wish to explore, even though we 
would likely only use a subset of them in our final model ensemble selection. 
```{r, message = FALSE}
```

#' -----10--------20--------30--------40--------50--------60--------70--------80--------90


### Step 6 (extended): Build a validator to select a model ensemble
We now validate and select our new extended model ensemble via the *Validator* class,
again using the default ABC approach (via the *abc* library). 
which by
default utilizes an approximate Bayesian computation (ABC) approach (Beaumont, Zhang, 
& Balding, 2002) provided by the *abc* library (Csillery et al., 2015). We will use the 
default configuration to select the best 100 models (via a *tolerance* of 0.01). Our
targets for selecting the best models will be: a total bounty submission of 2041 
*thylacines*, derived from historic bounty records [REF]; and an estimated extinction
date of 1934, the midpoint of last capture (1931) and sighting (1937) records [REF].
Note that for models where our simulated *thylacine* persist until the end of the
simulation (1967), the extirpation value returned will be *NA*. Since the *abc* 
function requires finite values only, we will use the *non_finite_replacements* 
attribute of the validator to replace these *NA* values with 1968.


#' -----10--------20--------30--------40--------50--------60--------70--------80--------90

## References
Allee, W. C. (1931). *Animal Aggregations: A Study in General Sociology*. University of 
Chicago Press.

Beaumont, M. A., Zhang, W., & Balding, D. J. (2002). 'Approximate Bayesian computation
in population genetics'. *Genetics*, vol. 162, no. 4, pp, 20252035.

Bulte, E. H., Horan, R. D., & Shogren, J. F. (2003). 'Is the Tasmanian tiger extinct? 
A biologicaleconomic re-evaluation', *Ecological Economics*, vol. 45, no. 2, 
pp. 271279.

Csillery, K., Lemaire L., Francois O., & Blum M. (2015). 'abc: Tools for Approximate 
Bayesian Computation (ABC)'. *R package version 2.1*. Retrieved from 
<https://CRAN.R-project.org/package=abc>

Grimm, V., Revilla, E., Berger, U., Jeltsch, F., Mooij, W. M., Railsback, S. F.,
Thulke, H. H., Weiner, J., Wiegand, T., DeAngelis, D. L., (2005). 'Pattern-Oriented
Modeling of Agent-Based Complex Systems: Lessons from Ecology'. *Science*
vol. 310, no. 5750, pp. 987991.

Guiler, E. (1985). *Thylacine: The Tragedy of the Tasmanian Tiger*. Oxford University
Press, Melbourne.

Guiler E. R. & Godard P. (1998). *Tasmanian tiger: a lesson to be learnt*. 
Abrolhos Publishing, Perth, Western Australia.

Ricker, W. E. (1954). 'Stock and recruitment'. 
*Journal of the Fisheries Research Board of Canada*,  vol. 11, no. 5, pp. 559-623.
